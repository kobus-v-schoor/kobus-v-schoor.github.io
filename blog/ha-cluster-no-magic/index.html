<!doctype html><html lang=en><head><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-155995545-2','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta property="og:title" content="Building a high-availability cluster without using magic"><meta property="og:description" content="Building a high-availability cluster from the ground up using Pacemaker"><meta property="og:type" content="article"><meta property="og:url" content="https://kobusvs.co.za/blog/ha-cluster-no-magic/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2021-02-28T10:14:18+02:00"><meta property="article:modified_time" content="2021-02-28T10:14:18+02:00"><link rel=icon type=image/svg href=/img/favicon.svg><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/main.css><link rel=stylesheet href=/css/highlight.css><title>Building a High-Availability Cluster Without Using Magic · Kobus van Schoor</title></head><body><nav class="d-md-none navbar navbar-expand flex-column navbar-dark text-light navbar-custom"><a href=https://kobusvs.co.za/ class=navbar-brand><img src=/img/mobile-logo.svg width=30 height=30>
Kobus van Schoor</a><ul class=navbar-nav><li class="nav-item text-center"><a class=nav-link href=https://kobusvs.co.za/><i data-feather=home></i>Home</a></li><li class="nav-item text-center"><a class=nav-link href=https://kobusvs.co.za/about/><i data-feather=user></i>About</a></li><li class="nav-item text-center"><a class=nav-link href=/files/Kobus%20van%20Schoor%20-%20Resume.pdf><i data-feather=file-text></i>Resume</a></li><li class="nav-item text-center"><a class=nav-link href=https://kobusvs.co.za/blog/><i data-feather=feather></i>Blog</a></li></ul></nav><div class=container-fluid><div class=row><nav class="d-none d-md-flex col-md-3 col-lg-2 flex-column align-items-start sidebar"><a href=https://kobusvs.co.za/ class="text-center w-100"><img src=/img/logo.svg class="mt-3 desktop-logo"></a><h5 class="align-self-center pt-3">Kobus van Schoor</h5><small class="align-self-center mb-3"><i class=f-16 data-feather=map-pin></i>Pretoria, South Africa</small>
<span class="align-self-center d-flex flex-row"><a href=https://github.com/kobus-v-schoor/ class=social><i data-feather=github></i></a>
<a href=https://www.linkedin.com/in/kobus-van-schoor class=social><i data-feather=linkedin></i></a>
<a href=mailto:v.schoor.kobus@gmail.com class=social><i data-feather=mail></i></a></span><hr><a class=sidebar-link href=https://kobusvs.co.za/><i data-feather=home></i>
Home</a>
<a class=sidebar-link href=https://kobusvs.co.za/about/><i data-feather=user></i>
About me</a>
<a class=sidebar-link href=https://kobusvs.co.za/resume/><i data-feather=file-text></i>
Resume</a>
<a class=sidebar-link href=https://kobusvs.co.za/tags/projects/><i data-feather=cpu></i>
Projects</a>
<a class=sidebar-link href=https://kobusvs.co.za/blog/><i data-feather=feather></i>
Blog</a>
<small class="mt-auto align-self-center">&copy; 2021 Kobus van Schoor</small></nav><main class="col-md-9 col-lg-10"><div class="container mt-5 mb-5"><div class=row><article class=col-xl-8><h1>Building a high-availability cluster without using magic</h1><div class="text-muted d-flex flex-column flex-md-row align-md-items-center mb-3"><span><i data-feather=clock></i>5 minutes</span>
<span class=ml-md-2><i data-feather=calendar></i>28 Feb 2021</span>
<span><i class=ml-md-2 data-feather=tag></i><a class=text-secondary href=https://kobusvs.co.za/tags/linux/>linux</a>, <a class=text-secondary href=https://kobusvs.co.za/tags/high-availability/>high-availability</a></span></div><p>There are incredibly powerful tools available to build and manage
high-availability clusters these days, the most popular probably being
Kubernetes. These tools are can do amazing things, and if you&rsquo;ve ever seen them
in action you&rsquo;ll know they look like magic. When considering
my options for a recent project I wanted to opt for a simpler solution when I
was setting up a high-availability cluster for an HPC environment. Note that I
don&rsquo;t mean simpler in terms of how easy it is to use, but rather simplicity in
terms of how much the tool does (insert some generic systemd comment here).
Let&rsquo;s break down what we need from a high-availability cluster and then
investigate how we can solve each problem on its own.</p><p>Note that if you&rsquo;re planning on managing millions of containers this approach
probably won&rsquo;t scale well, but if you have a few dozen services and just want a
simple solution to keep them running this might be an option.</p><h2 id=high-availability-what-do-we-need>High availability: what do we need?</h2><p>In its simplest form, we need our infrastructure to be robust against one or
more nodes failing or becoming unavailable. To that end, we will require the
following:</p><ul><li>Something to monitor, manage and move around resources</li><li>A distributed storage solution on which we can run resources and store their
data</li></ul><p>Resources here can be anything: VMs, containers or even just an Apache
installation. You&rsquo;ll soon see that you can plug just about anything into this
setup. To make this happen we&rsquo;ll be using
<a href=https://www.clusterlabs.org/pacemaker/>Pacemaker</a>, a high-availability
resource manager that is incredibly flexible and easy to adapt to your exact
needs.</p><p>As for the distributed storage solution I&rsquo;ve opted to use
<a href=https://ceph.io/>Ceph</a>, a personal favourite of mine (and also
<a href=https://www.hpcwire.com/2019/09/30/how-ceph-is-helping-to-unlock-the-secrets-of-the-universe/>CERN</a>,
but who cares about that). It provides excellent reliability and is simple to
set up and use. Once set up you&rsquo;ll be left with one or more block devices in
<code>/dev/rbd</code> that you can use just like a normal storage devices. You can however
use any other distributed storage solution that you&rsquo;d like by just adapting the
resource scripts we&rsquo;ll be setting up in the next sections.</p><h2 id=pacemaker-the-heartbeat-of-the-cluster>Pacemaker: the heartbeat of the cluster</h2><p>Pacemaker is a cluster resource manager - think of it like a distributed,
highly-available init system. It starts, stops and monitors services on various
nodes and makes sure that everything keeps on running. The cool thing is that
resources are essentially just scripts that you can set up to fit your exact
needs. Pacemaker then takes care of managing your resource via your provided
script - if your script says the resource is down, Pacemaker can automatically
start it up on another node. It&rsquo;s that simple™. Let&rsquo;s take a look at an
(incomplete) example Pacemaker resource script (the proper name is a &ldquo;resource
agent&rdquo;) that is meant to make sure that Apache is running:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#6272a4># NOTE this is not a valid resource agent but this is essentially how they work</span>
<span style=color:#6272a4># A valid resource agent will have some extra boilerplate and needs to return</span>
<span style=color:#6272a4># specific values from the various functions</span>

start<span style=color:#ff79c6>()</span> <span style=color:#ff79c6>{</span>
    <span style=color:#6272a4># here we can start some service, for example apache</span>
    systemctl start apache2
<span style=color:#ff79c6>}</span>

stop<span style=color:#ff79c6>()</span> <span style=color:#ff79c6>{</span>
    <span style=color:#6272a4># here we need to stop whatever we started</span>
    systemctl stop apache2
<span style=color:#ff79c6>}</span>

monitor<span style=color:#ff79c6>()</span> <span style=color:#ff79c6>{</span>
    <span style=color:#6272a4># here we need to check if the resource is still running and inform</span>
    <span style=color:#6272a4># pacemaker if there is any issues</span>
    systemctl status apache2 &amp;&gt; /dev/null
    <span style=color:#ff79c6>return</span> <span style=color:#8be9fd;font-style:italic>$?</span>
<span style=color:#ff79c6>}</span>
</code></pre></div><p>Resource agents are incredibly flexible - have a look that the <a href=https://github.com/ClusterLabs/resource-agents/tree/master/heartbeat>ClusterLabs
resource agents
repo</a>
which contains a bunch of examples to get you started. You can also read <a href=http://www.linux-ha.org/wiki/OCF_Resource_Agents>this
short introduction</a>, and when
you&rsquo;re ready <a href=http://www.linux-ha.org/doc/dev-guides/ra-dev-guide.html>here is detailed
documentation</a> for
resource agent development.</p><p>Pacemaker allows you to configure how you want to orchestrate your resources in
a myriad of ways (e.g. node affinity, resource constraints and load balancing
just to name a few). Pacemaker even supports cool things like STONITH (Shoot
The Other Node In The Head) where it can trigger hardware power switches to
power off misbehaving nodes. Be sure to read through the <a href=https://clusterlabs.org/pacemaker/doc/>official
documentation</a> to set up Pacemaker and
check out what it allows you to do.</p><h2 id=high-availability-storage>High-availability storage</h2><p>Once you have Pacemaker up and running you will need some way to share data
between your nodes: this is where Ceph comes in. Ceph is a distributed, highly
scalable and reliable storage solution that allows you to combine multiple
nodes into one big clustered storage pool. You can then access your data from
any of these nodes as if they had a native hard-drive plugged in (assuming
you&rsquo;re using Ceph&rsquo;s RBD images). Ceph also provides data redundancy, automatic
fail-over and data scrubbing all while being easy to set up and use. Ceph has
fantastic documentation - be sure to check it out <a href=https://docs.ceph.com/en/stable/>the official documentation
here</a>.</p><p>Ceph is by no means the only distributed storage solution, there is also
<a href=https://www.gluster.org/>Gluster</a>, <a href=https://www.openafs.org/>OpenAFS</a> or
even just plain old NFS. As long as you have some way for your various nodes to
access the resource data (databases, VM hard-drives etc.) you will be able to
adapt your resource agents to use them.</p><h2 id=putting-it-all-together>Putting it all together</h2><p>Now we have a way to orchestrate our resources and using the distributed
storage we can access our resource data from various nodes. It is now simply a
matter of choosing what your resources should be and deploying them. Some
examples of possible deployments (each of them using some distributed
filesystem for data storage):</p><ul><li>VMs managed with <code>libvirt</code></li><li>MariaDB server</li><li>Nginx load balancer</li></ul><p>Below you can see a resource agent that uses an LXC + Ceph deployment which I&rsquo;m
currently using in a HPC project. The resource agent essentially does the
following:</p><ul><li>LXC containers are each stored on their own RBD image which are formatted
using EXT4</li><li>To start a container the RBD image is mapped to one node and is then mounted
inside <code>/var/lib/lxc/&lt;container-name></code> on that node</li><li>Starts the container using <code>lxc-start</code> after it is mounted</li><li>Stops the container using <code>lxc-stop</code>, after which it unmounts the container
image and unmaps the Ceph RBD image</li><li>Monitors the container using <code>lxc-ls</code></li></ul><p>This deployment has been serving me well for over two years and it currently
manages around 70 LXC containers with around 5.5TB of data without any
problems.</p><script type=application/javascript src=https://gist.github.com/kobus-v-schoor/0d2408f9052ce08949fd9b8caf08e170.js></script></article><aside class="d-none d-xl-block col-xl"><div id=toc><h4 class="mt-5 text-muted">Table of Contents</h4><nav id=TableOfContents><ul><li><a href=#high-availability-what-do-we-need>High availability: what do we need?</a></li><li><a href=#pacemaker-the-heartbeat-of-the-cluster>Pacemaker: the heartbeat of the cluster</a></li><li><a href=#high-availability-storage>High-availability storage</a></li><li><a href=#putting-it-all-together>Putting it all together</a></li></ul></nav></div></aside></div></div></main><span class="d-md-none text-muted text-center w-100">&copy; 2021 Kobus van Schoor</span></div></div><script src=/js/jquery-3.5.1.slim.min.js></script><script src=/js/bootstrap.bundle.min.js></script><script src=/js/feather.min.js></script><script>feather.replace()</script><script>var toc=$('#TableOfContents').children('ul').addClass('list-group');toc=toc.find('li').addClass('list-group-item'),toc=toc.find('a').addClass('text-dark')</script></body></html>